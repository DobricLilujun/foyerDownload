{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PDF image extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz\n",
    "import pytesseract\n",
    "from pdf2image import convert_from_path\n",
    "from PIL import Image\n",
    "import io\n",
    "import base64\n",
    "\n",
    "\n",
    "def pil_image_to_base64(pil_images, format=\"PNG\"):\n",
    "    img_base64_list = []\n",
    "    for image in pil_images:\n",
    "        buffer = io.BytesIO()\n",
    "        image.save(buffer, format=format)\n",
    "        img_bytes = buffer.getvalue()\n",
    "        img_base64 = base64.b64encode(img_bytes).decode(\"utf-8\")\n",
    "        img_base64_list.append(img_base64)\n",
    "    return img_base64_list\n",
    "\n",
    "\n",
    "def extract_images_from_pdf(pdf_path):\n",
    "    pdf_document = fitz.open(pdf_path)\n",
    "    images = []\n",
    "\n",
    "    for page_number in range(len(pdf_document)):\n",
    "        page = pdf_document.load_page(page_number)\n",
    "        image_list = page.get_images(full=True)\n",
    "\n",
    "        for image_index, img in enumerate(image_list):\n",
    "            xref = img[0]\n",
    "            base_image = pdf_document.extract_image(xref)\n",
    "            image_bytes = base_image[\"image\"]\n",
    "            image_ext = base_image[\"ext\"]\n",
    "            image = Image.open(io.BytesIO(image_bytes))\n",
    "\n",
    "            # image_file = f\"extracted_image_{page_number+1}_{image_index+1}.{image_ext}\"\n",
    "            images.append(image)\n",
    "\n",
    "    return images\n",
    "\n",
    "\n",
    "def extract_text_from_image(image):\n",
    "    text = pytesseract.image_to_string(image)\n",
    "    return text\n",
    "\n",
    "\n",
    "def find_top_k_length(list_text, top_k=2):\n",
    "    sorted_indexs = sorted(\n",
    "        range(len(list_text)), key=lambda i: list_text[i], reverse=True\n",
    "    )\n",
    "    top_k_indexs = sorted_indexs[:top_k]\n",
    "    return top_k_indexs, [images[i] for i in top_k_indexs]\n",
    "\n",
    "\n",
    "# PDF Extraction testing for detecting the length\n",
    "pdf_path = \"test.pdf\"\n",
    "images = extract_images_from_pdf(pdf_path)\n",
    "text_length_list = []\n",
    "for img in images:\n",
    "    text = extract_text_from_image(img)\n",
    "    text_length_list.append(len(text))\n",
    "\n",
    "top_k = 2\n",
    "top_k_indexs, top_k_images = find_top_k_length(list_text=text_length_list, top_k=top_k)\n",
    "\n",
    "# Extract valuatble Text from image -  Test_On_MiniCPM with corresponding json prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_k_images_path = []\n",
    "for i in range(top_k):\n",
    "    path = f\"temp/temp_{i}.jpg\"\n",
    "    top_k_images_path.append(path)\n",
    "    top_k_images[i].save(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Title:**\n",
      "\"未来世界·华语童声”国际青少年艺术展演亮相首届教科文电影遗产国际电影节\n",
      "\n",
      "**Subtitle:** \n",
      "欧洲时报 华侨周末 2023年12月1日-3日\n",
      "\n",
      "**Date:** \n",
      "周五一星期五 日 - 星期六 日 (01 Dec 2023)\n",
      "\n",
      "**Body Text:**\n",
      "\"未来世界·华语童声”国际青少年艺术展演亮相首届教科文电影遗产国际电影节\n",
      "(欧洲时报记者/李倩)为纪念联合国教科文组织设立世界电影日1954年12月7日，中国电影资料馆主办的“未来世界·华语童声”国际青少年艺术展演于10月3日在国家大剧院举行。活动以弘扬中华优秀传统文化和传播电影文化为核心，旨在通过音乐、戏剧、舞蹈等艺术形式展示青少年的艺术才华与创造力。\n",
      "\n",
      "**Additional Text:**\n",
      "- 李倩：中国未来世界·华语童声艺术展演\n",
      "  - 这次展演是首次在国家大剧院举办，吸引了来自全国各地的60余位青少年演员参与。\n",
      "  \n",
      "- 郑凯：教科文组织副部长李明华致辞\n",
      "  - 她表示，此次展演活动不仅有助于推广中华优秀传统文化，也有助于促进中外文化交流。\n",
      "\n",
      "**Images Description:**\n",
      "The images depict various scenes from the event, including participants performing on stage and engaging with audiences.\n",
      "\n",
      "- Image captions include:\n",
      "  - \"郑凯：教科文组织副部长李明华致辞\"\n",
      "  - \"未来世界·华语童声艺术展演”\n",
      "  - \"青少年演员在舞台上表演\"\n",
      "  - \"观众积极参与互动\"\n",
      "\n",
      "**Footer:**\n",
      "(底部有彩条和色标，表明这是一份报纸的版面)\n",
      "\n",
      "(Note: The text has been transcribed as accurately as possible from the image, preserving names and titles.)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import ollama\n",
    "\n",
    "prompt_extraction = \"\"\"Extract all of the text in the image.\"\"\"\n",
    "\n",
    "\n",
    "def run_inference(model: str, image_paths: str):\n",
    "    stream = ollama.chat(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt_extraction,\n",
    "                \"images\": [image_paths],\n",
    "            }\n",
    "        ],\n",
    "        stream=True,\n",
    "    )\n",
    "\n",
    "    for chunk in stream:\n",
    "        print(chunk[\"message\"][\"content\"], end=\"\", flush=True)\n",
    "\n",
    "\n",
    "run_inference(\"minicpm-v:8b\", \"temp/temp_0.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: {'model': 'minicpm-v:8b', 'created_at': '2024-09-27T10:28:41.138506Z', 'response': '', 'done': True, 'done_reason': 'load'}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "top_k_images_base_64 = pil_image_to_base64(top_k_images)\n",
    "\n",
    "url = \"http://localhost:11434/api/generate\"\n",
    "data = {\n",
    "    \"model\": \"minicpm-v:8b\",\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"What's the main information about these photos\",\n",
    "            \"images\": top_k_images_base_64,\n",
    "        }\n",
    "    ],\n",
    "}\n",
    "\n",
    "\n",
    "response = requests.post(url, json=data)\n",
    "\n",
    "# Print the response\n",
    "if response.status_code == 200:\n",
    "    print(\"Response:\", response.json())\n",
    "else:\n",
    "    print(f\"Failed to get a response. Status code: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "model = AutoModel.from_pretrained(\n",
    "    \"openbmb/MiniCPM-V-2_6\",\n",
    "    trust_remote_code=True,\n",
    "    attn_implementation=\"sdpa\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    ")  # sdpa or flash_attention_2, no eager\n",
    "model = model.eval().cuda()\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"openbmb/MiniCPM-V-2_6\", trust_remote_code=True\n",
    ")\n",
    "\n",
    "image = Image.open(\"test_image.jpg\").convert(\"RGB\")\n",
    "question = \"What is in the image?\"\n",
    "msgs = [{\"role\": \"user\", \"content\": [image, question]}]\n",
    "\n",
    "res = model.chat(image=None, msgs=msgs, tokenizer=tokenizer)\n",
    "print(res)\n",
    "\n",
    "## if you want to use streaming, please make sure sampling=True and stream=True\n",
    "## the model.chat will return a generator\n",
    "res = model.chat(image=None, msgs=msgs, tokenizer=tokenizer, sampling=True, stream=True)\n",
    "\n",
    "generated_text = \"\"\n",
    "for new_text in res:\n",
    "    generated_text += new_text\n",
    "    print(new_text, flush=True, end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "causalAnalysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
