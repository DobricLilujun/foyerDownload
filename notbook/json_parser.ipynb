{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Any, Dict, Iterator, List, Mapping, Optional\n",
    "import requests\n",
    "from langchain_core.callbacks.manager import CallbackManagerForLLMRun\n",
    "from langchain_core.language_models.llms import LLM\n",
    "from langchain_core.outputs import GenerationChunk\n",
    "from enum import Enum\n",
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmailParser(BaseModel):\n",
    "    email_sender: str = Field(\n",
    "        description=\"The email address of the sender, indicating who sent the email.\"\n",
    "    )\n",
    "    email_receiver: str = Field(\n",
    "        description=\"The email address of the recipient, indicating who is intended to receive the email.\"\n",
    "    )\n",
    "    email_body: str = Field(\n",
    "        description=\"The main content of the email, which may include text, links, or other information. This field represents the message being conveyed from the sender to the receiver.\"\n",
    "    )\n",
    "\n",
    "# Send request to local ollama server for testing \n",
    "def send_request():\n",
    "    url = \"http://localhost:11434/api/generate\"\n",
    "    data = {\n",
    "        \"model\": \"minicpm-v:8b\",\n",
    "        \"prompt\": \"Why is the sky blue?\",\n",
    "        \"stream\": False,\n",
    "        \"options\": {\n",
    "            \"temperature\": 0\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    headers = {'Content-Type': 'application/json'}\n",
    "    \n",
    "    response = requests.post(url, data=json.dumps(data), headers=headers)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        return f\"Error: {response.status_code}, {response.text}\"\n",
    "\n",
    "\n",
    "\n",
    "# Wrapper of lanchain to call local LLM API\n",
    "class CustomLLM(LLM):\n",
    "# https://python.langchain.com/docs/how_to/custom_llm/ \n",
    "    url: str\n",
    "    is_stream: bool\n",
    "    model: str\n",
    "    model_path: str\n",
    "    temperature: float = 0.7\n",
    "\n",
    "    def _call(\n",
    "        self,\n",
    "        prompt: str,\n",
    "        stop: Optional[List[str]] = None,\n",
    "        run_manager: Optional[CallbackManagerForLLMRun] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> str:\n",
    "        print (self.temperature)\n",
    "        data = {\n",
    "            \"model\": self.model,\n",
    "            \"prompt\": prompt,\n",
    "            \"stream\": self.is_stream,\n",
    "            \"options\": {\n",
    "                \"temperature\": self.temperature\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        headers = {'Content-Type': 'application/json'}\n",
    "        response = requests.post(url=self.url, json=data, headers=headers)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            response_data = response.json()\n",
    "            # Assuming the API response contains the generated text in a field like 'output'\n",
    "            return response_data.get(\"response\") # Return n characters from the output\n",
    "        else:\n",
    "            raise RuntimeError(f\"Error {response.status_code}: {response.text}\")\n",
    "\n",
    "\n",
    "    @property\n",
    "    def _llm_type(self) -> str:\n",
    "        \"\"\"Get the type of language model used by this chat model. Used for logging purposes only.\"\"\"\n",
    "        return \"custom\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "email = \"\"\"\n",
    "\n",
    "From: <lujun.li@EMC.lu>\n",
    "To: <Jacob.Alex@foyer.lu>\n",
    "Dear Jacob,  \n",
    "  \n",
    "Except my fault, we didn't receive your reply yet since my last email for my request of reinbursement on the car accident. \n",
    "  \n",
    "\n",
    "Thank you for your participation!  \n",
    "  \n",
    "EMC Research is a national market and opinion research firm that conducts\n",
    "research on a variety of topics. We are not trying to sell anything, and your\n",
    "responses will remain completely anonymous. To learn more about EMC Research,\n",
    "go to www.emcresearch.com.  \n",
    "  \n",
    "Follow the link to opt out of future emails:  \n",
    "Click here to unsubscribe\n",
    "\n",
    "\n",
    "-----------\n",
    "\n",
    "Dear Jacob,  \n",
    "  \n",
    "Your opinion matters to us!  \n",
    "  \n",
    "You are invited to participate in a short survey about local transportation\n",
    "issues in the Bay Area.  Your opinions will be used for research purposes only\n",
    "and your responses will remain completely confidential.  \n",
    "  \n",
    "Follow this link to the Survey:  \n",
    "Take the Survey  \n",
    "  \n",
    "Or copy and paste the URL below into your internet browser:  \n",
    "https://thepollingplace.qualtrics.com/jfe/form/SV_aibZ5geNkxuBng2?Q_DL=4BQDYnCmFixO9bW_aibZ5geNkxuBng2_CGC_wYZc0ZnW5tL60xa&Q_CHL=email  \n",
    "  \n",
    "Thank you for your participation!  \n",
    "  \n",
    "EMC Research is a national market and opinion research firm that conducts\n",
    "research on a variety of topics. We are not trying to sell anything, and your\n",
    "responses will remain completely anonymous. To learn more about EMC Research,\n",
    "go to www.emcresearch.com.  \n",
    "  \n",
    "Follow the link to opt out of future emails:  \n",
    "Click here to unsubscribe\n",
    "\n",
    "\n",
    "Bamboo Spa Grand Reopening Sale!\n",
    "\n",
    "|  |  \n",
    "---  \n",
    "|\n",
    "\n",
    "4 Options Starting From\n",
    "\n",
    "$70.00  \n",
    "  \n",
    "  \n",
    "---  \n",
    "  \n",
    "\n",
    "View Offer  \n",
    "  \n",
    "What We're Offering\n",
    "\n",
    "**Join in our reopening celebration today by enjoying exclusive offers on\n",
    "your preferred services!**\n",
    "\n",
    "Unwind and rejuvenate yourself with our exclusive packages of **Foot\n",
    "Reflexology** , **Tension Tamer** , and **CustomBlend Massage**.\n",
    "\n",
    "Make sure to visit us for our inaugural=C2=A0 **Halloween celebration on\n",
    "October 27th, from 3pm-6pm </strong> (admission is free), where you can\n",
    "indulge in delightful treats and take advantage of amazing deals **RSVP**\n",
    "**.** For further details aboutthis month's promotions, kindly refer to our\n",
    "**=C2=A0** **Specials Page.\n",
    "\n",
    "**Special Offers for the Grand Reopening!**\n",
    "\n",
    "****__* 1 hr Foot Reflexology $70__\n",
    "\n",
    "____* 30 min Tension Tamer Massage + 30 min Foot Reflexology$85__\n",
    "\n",
    "____* 60 min Custom Blend Massage $105__\n",
    "\n",
    "____* 90 min Custom Blend Massage $125__\n",
    "\n",
    "**Foot Reflexology:=C2=A0** Revitalizing and refreshing the feet and legs is\n",
    "accomplished by stimulating key pressure points either manually or using a\n",
    "reflexology stick, through foot reflexology.\n",
    "\n",
    "**Tension Tamer:=C2=A0** Ease tension in your neck or unwindwith a soothing\n",
    "scalp massage. Upon request, enjoy essential oils or lotion; otherwise\n",
    "receive a dry treatment.\n",
    "\n",
    "**Custom Blend Massage:** =C2=A0Our expert therapists with awealth of\n",
    "experience will skillfully combine various techniques to relievetension,\n",
    "promote relaxation and provide relief for your muscles.\n",
    "\n",
    "For questions or more information, please call 415-567-8812 or visit our=\n",
    "website at http://www.bamboospasf.com.  \n",
    "  \n",
    "|  \n",
    "\n",
    "Bamboo Spa SF\n",
    "\n",
    "415-567-8812\n",
    "\n",
    "www.bamboospasf.com\n",
    "\n",
    "frontdesk@bamboospasf.com\n",
    "\n",
    "|\n",
    "\n",
    "|\n",
    "\n",
    "2284 Union St  \n",
    "San Francisco, CA 94123  \n",
    "  \n",
    "---  \n",
    "  \n",
    "|  Find more local experiences and promotions  \n",
    "|\n",
    "\n",
    "  \n",
    "\n",
    "|  \n",
    "  \n",
    "---|---  \n",
    "This email was created by Hownd on behalf of Bamboo Spa SF  \n",
    "(Located at 2284 Union St, San Francisco, CA, 94123).  \n",
    "  \n",
    "  \n",
    "Please review our Privacy Policy.  \n",
    "Unsubscribe to stop receiving this email.  \n",
    "Manage Privacy\n",
    "\"\"\"\n",
    "\n",
    "criteria = \"\"\"\n",
    "1. The sender are waiting for a response from the receiver.\n",
    "2. The email is a reminder of a past request.\n",
    "3. The email is a reminder of a reminder.\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The color of the sky appears to be a shade of blue because it reflects sunlight. The Earth's atmosphere scatters light in all directions, but short-wavelength visible light (blue and violet) are scattered more than others due to their shorter wavelengths. This scattering effect causes most of this light to scatter into our eyes from every direction we look at the sky during daylight hours.\n",
      "\n",
      "The reason why blue is a dominant color for sunlight that reaches us on Earth's surface, as opposed to other colors like red or green, has to do with how much each wavelength scatters in different directions. Blue and violet wavelengths are scattered more than others because they have shorter wavelengths which means their particles move faster through the air molecules before hitting another one.\n",
      "\n",
      "The scattering of light is also why we see stars at night as bright points instead of diffuse disks like during daytime when all visible light from a star has been scattered in every direction by Earth's atmosphere.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize local LLM model for calling\n",
    "\n",
    "llm = CustomLLM(url = \"http://localhost:11434/api/generate\",is_stream = False,  model = \"minicpm-v:8b\", model_path=\"minicpm-v:8b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7\n"
     ]
    }
   ],
   "source": [
    "# Define the Chain\n",
    "from pydantic import ValidationError\n",
    "parser = JsonOutputParser(pydantic_object=EmailParser)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"Can you provide details or insights on the very first email found at the top of the document below? \\nMake sure to answer in the following format.{format_instructions}.\\nHere is the document:\\n{input}\",\n",
    "    input_variables=[\"input\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "chain = prompt | llm | parser\n",
    "\n",
    "llm.temperature = 0.7\n",
    "def invoke_chain_with_retry(input_data, max_retries=10):\n",
    "    attempts = 0\n",
    "    while attempts < max_retries:\n",
    "        response = chain.invoke({\"input\": input_data})\n",
    "        return response  # Successfully parsed output\n",
    "\n",
    "# Call the function with the email input\n",
    "result = invoke_chain_with_retry(email)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'email_sender': 'lujun.li@EMC.lu',\n",
       " 'email_receiver': 'Jacob.Alex@foyer.lu',\n",
       " 'email_body': \"Dear Jacob,\\n\\nExcept my fault, we didn't receive your reply yet since my last email for my request of reinbursement on the car accident.\\n\\nThank you for your participation!\\n\\nEMC Research is a national market and opinion research firm that conducts research on a variety of topics. We are not trying to sell anything, and your responses will remain completely anonymous. To learn more about EMC Research,\\ngo to www.emcresearch.com.\\n\\nFollow the link to opt out of future emails: Click here to unsubscribe\",\n",
       " 'email_type': 'reminder'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7\n"
     ]
    }
   ],
   "source": [
    "class EmailClassification(BaseModel):\n",
    "    is_reminder: bool = Field(\n",
    "        description=\"Whether the email document is classified as a reminder email.\"\n",
    "    )\n",
    "    justification: str = Field(\n",
    "        description=\"Explanation of why the email is classified as a reminder.\"\n",
    "    )\n",
    "\n",
    "\n",
    "parser = JsonOutputParser(pydantic_object=EmailClassification)\n",
    "prompt = PromptTemplate(\n",
    "    template=\"Can you please tell classfify whether the document is a 'reminder' according to one of the following the criteria? {criteria} \\nMake sure to answer in the following format.{format_instructions}.\\nHere is the document:\\n{input}\",\n",
    "    input_variables=[\"criteria\", \"input\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "chain = prompt | llm | parser\n",
    "\n",
    "llm.temperature = 0.7\n",
    "def invoke_chain_with_retry(max_retries=10):\n",
    "    attempts = 0\n",
    "    while attempts < max_retries:\n",
    "        response = chain.invoke({\"criteria\": criteria, \"input\": result[\"email_body\"]})\n",
    "        return response  # Successfully parsed output\n",
    "\n",
    "# Call the function with the email input\n",
    "output = invoke_chain_with_retry()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: dfasdf\n",
      "\"\n",
      "\n",
      "             \n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "example_prompt = PromptTemplate.from_template(\"Question: {question}\\n{answer}\")\n",
    "\n",
    "examples = [\n",
    "            {\"question\": \"dfasdf\",\"answer\": \"\"\"\n",
    "\n",
    "             \"\"\"}, \n",
    "            {\"question\": \"dfasdf\",\"answer\": \"\"\"\n",
    "\n",
    "             \"\"\"}]\n",
    "\n",
    "print(example_prompt.invoke(examples[0]).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: dfasdf\n",
      "\"\n",
      "\n",
      "             \n",
      "\n",
      "Question: dfasdf\n",
      "\"\n",
      "\n",
      "             \n",
      "\n",
      "Question: Who was the father of Mary Ball Washington?\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import FewShotPromptTemplate\n",
    "\n",
    "prompt = FewShotPromptTemplate(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    "    suffix=\"Question: {input}\",\n",
    "    input_variables=[\"input\"],\n",
    ")\n",
    "\n",
    "print(\n",
    "    prompt.invoke({\"input\": \"Who was the father of Mary Ball Washington?\"}).to_string()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "causalAnalysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
