{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import MarianMTModel, MarianTokenizer\n",
    "\n",
    "\n",
    "# Helsinki-NLP/opus-mt-mul-en liscence can be used commercially\n",
    "# Why we need this because we think that that minicpm is efficient\n",
    "def translate_text(\n",
    "    input_text: str, model_name: str = \"Helsinki-NLP/opus-mt-mul-en\"\n",
    ") -> str:\n",
    "    tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
    "    model = MarianMTModel.from_pretrained(model_name)\n",
    "    translated = model.generate(\n",
    "        **tokenizer([input_text], return_tensors=\"pt\", padding=True)\n",
    "    )\n",
    "    return tokenizer.decode(translated[0], skip_special_tokens=True)\n",
    "\n",
    "\n",
    "input_text = \"\"\"L'extraction de l'information fait partie d'un plus grand casse-tête qui traite du problème de la conception de méthodes automatiques de gestion du texte, au-delà de sa transmission, de son stockage et de son affichage. La discipline de l'extraction de l'information (IR)[3] a développé des méthodes automatiques, généralement d'une saveur statistique, pour l'indexation des grandes collections de documents et la classification des documents. Une autre approche complémentaire est celle du traitement du langage naturel (NLP) qui a résolu le problème de la modélisation du traitement du langage humain avec un succès considérable en tenant compte de l'ampleur de la tâche. En termes de difficulté et d'importance, IE traite des tâches entre IR et NLP. En termes d'entrée, IE suppose l'existence d'un ensemble de documents dans lequel chaque document suit un modèle, c'est-à-dire décrit une ou plusieurs entités ou événements d'une manière similaire à ceux d'autres documents mais différente dans les détails.\"\"\"\n",
    "output_text = translate_text(input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "extraction_prompt_template = \"\"\"Given the following large text string that contains multiple email messages, please extract the content of the first email you discover. Ensure to include the following details in your response:\n",
    "\n",
    "\t1.\tSender (From)\n",
    "\t2.\tRecipient (To)\n",
    "\t3.\tSubject (Subject)\n",
    "\t4.\tBody of the email\n",
    "\n",
    "Please format your response as follows:\n",
    "\n",
    "\t•\tFrom: [Sender]\n",
    "\t•\tTo: [Recipient]\n",
    "\t•\tSubject: [Subject]\n",
    "\t•\tBody: [Body content]\n",
    "\n",
    "Here is the text string to analyze:\n",
    "\n",
    "{CONTEXT_STRING}\n",
    "\"\"\"\n",
    "\n",
    "classfication_prompt_template = \"\"\"\"\"Based on the following email content, please analyze whether the company needs to take action or respond. Consider the urgency, importance, and nature of the request or information in the email. Provide a recommendation with a brief justification.\n",
    "\n",
    "Here is the email content:\n",
    "\n",
    "{EMAIL_EXTRACTED}\n",
    "\n",
    "Please answer with one of the following options:\n",
    "\n",
    "\t1.\tAction Required: Explain what action is needed and why.\n",
    "\t2.\tNo Action Required: Explain why no action is necessary.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import PromptTemplate\n",
    "\n",
    "extraction_prompt_template = PromptTemplate(extraction_prompt_template)\n",
    "classfication_prompt_template = PromptTemplate(classfication_prompt_template)\n",
    "\n",
    "context_string = \"context**********\"\n",
    "\n",
    "## you can create text prompt (for completion API)\n",
    "prompt = extraction_prompt_template.format(\n",
    "    CONTEXT_STRING=context_string,\n",
    ")\n",
    "## inference for extraction\n",
    "extracted_email = \"context**********\"\n",
    "\n",
    "## get calssificaiton label using API"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "causalAnalysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
